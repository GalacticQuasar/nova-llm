# Nova LLM

A full-stack LLM agent workflow with custom tool calling capabilities and configuration with MCP servers.

## âœ¨ Features

- **Multiple Gemini Models**: Support for Gemini 2.5 Pro, 2.5 Flash, and 2.0 Flash
- **Model Context Protocol (MCP)**: Extensible tool system for enhanced AI capabilities
- **Custom Function Tools**: Example time and random number generation functions
- **Real-time Streaming**: Choose from chunk, word-by-word, or character-by-character streaming animations
- **Markdown rendering**: Real-time markdown rendering during generation
- **Copy Messages**: One-click copying of any message to clipboard
- **Configurable Settings**: Easy model switching and tool configuration for each message

## ðŸ—ï¸ Architecture

### Frontend (Client)
- **Framework**: React 19 with TypeScript
- **Build Tool**: Vite
- **Styling**: Tailwind CSS with custom design system
- **UI Components**: Shadcn/ui components with custom styling
- **State Management**: React Context for configuration
- **Markdown Rendering**: Full markdown support with syntax highlighting

### Backend (Server)
- **Runtime**: Node.js with Express
- **AI Integration**: Google GenAI SDK
- **MCP Support**: Model Context Protocol client for extensible tools
- **Streaming**: Server-sent events for real-time responses

## ðŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- Google Gemini API key

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/GalacticQuasar/nova-llm.git
   cd nova-llm
   ```

2. **Set up the server**
   ```bash
   cd server
   npm install
   ```

3. **Configure environment variables**
   ```bash
   # Create .env file in server directory
   echo "GEMINI_API_KEY=your_gemini_api_key_here" > .env
   echo "PORT=3000" >> .env
   ```

4. **Set up the client**
   ```bash
   cd ../client
   npm install
   ```

### Running the Application

1. **Start the server** (from server directory)
   ```bash
   npm start
   # or for development with auto-reload
   npm run watch
   ```

2. **Start the client** (from client directory)
   ```bash
   npm run dev
   ```

3. **Open your browser** to `http://localhost:5173`

## âš™ï¸ Configuration

### Model Selection
Choose from available Gemini models:
- **Gemini 2.5 Pro**
- **Gemini 2.5 Flash**
- **Gemini 2.0 Flash**

### Streaming Animation
Customize how responses appear:
- **Chunk**: Instant text blocks (fastest)
- **Word**: Word-by-word animation (balanced)
- **Character**: Character-by-character typing effect (smoothest)

### Function Tools
Enable/disable built-in functions:
- **Get Time**: Current time in specified timezone
- **Get Random Number**: Random number generation within range

> Note: You can add or change these tools, see [Adding Custom Tools](#adding-custom-tools)

### Model Context Protocol (MCP)
Toggle MCP mode to use external tool servers for extended functionality.

## ðŸ› ï¸ Development

### Project Structure

```
nova-llm/
â”œâ”€â”€ client/                 # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # UI components
â”‚   â”‚   â”œâ”€â”€ contexts/       # React contexts
â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom hooks
â”‚   â”‚   â”œâ”€â”€ api/            # API client
â”‚   â”‚   â””â”€â”€ types/          # TypeScript types
â”‚   â””â”€â”€ public/             # Static assets
â””â”€â”€ server/                 # Express backend
    â”œâ”€â”€ server.js           # Main server file
    â””â”€â”€ package.json        # Server dependencies
```

### Adding Custom Tools

1. **Define the function** in `server.js`:
   ```javascript
   const myCustomFunction = async (param1, param2) => {
     // Your implementation
     return result;
   };
   ```

2. **Add function declaration** to `geminiConfig`:
   ```javascript
   {
     name: "my_custom_function",
     description: "Description of what it does",
     parameters: {
       type: Type.OBJECT,
       properties: {
         param1: {
           type: Type.STRING,
           description: "Parameter description",
         },
       },
     },
   }
   ```

3. **Add the function call in the `handleFunctionCall` handler**:
   ```javascript
    async function handleFunctionCall(functionCall) {
        try {
            if (functionCall.name === "get_time") {
                return await getTime(functionCall.args.location);
            }
            if (functionCall.name === "get_random_number") {
                return await getRandomNumber(functionCall.args.min, functionCall.args.max);
            }
            // ADD YOUR FUNCTION CALL HERE IN THE HANDLER
            if (functionCall.name === "my_custom_function") {
                return await myCustomFunction(functionCall.args.param1, functionCall.args.param2);
            }
        } catch (error) {
            console.error(`Error handling function call ${functionCall.name}:`, error);
            return null;
        }
    }
   ```

## ðŸ”Œ Model Context Protocol (MCP)

Nova LLM supports MCP for extensible tool integration. MCP servers can be configured in the server initialization:

```javascript
const serverParams = new StdioClientTransport({
  command: "npx",
  args: ["your-mcp-server-package"]
});
```

When MCP mode is enabled, custom function tools are disabled in favor of MCP-provided tools.

## ðŸ“š API Reference

### POST `/api/stream`

Stream chat responses from Gemini models.

**Request Body:**
```json
{
  "messages": [
    {
      "role": "user|model",
      "content": "Message content"
    }
  ],
  "config": {
    "model": "gemini-2.5-flash",
    "tools": {
      "get_time": true,
      "get_random_number": false
    },
    "mcpEnabled": false,
    "streamType": "Word"
  }
}
```

**Response:** Server-sent events with text chunks